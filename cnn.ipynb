{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 18:20:50.656984: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-10 18:20:50.721056: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-10 18:20:50.721098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-10 18:20:50.723411: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-10 18:20:50.733639: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-10 18:20:50.734651: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-10 18:20:51.945809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import utils as ut\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ut.loadData(\"./models/data_binary\")\n",
    "labels = ut.loadData(\"./models/labels\")\n",
    "classes = ut.loadData(\"./models/classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(labels)):\n",
    "    id = classes[labels[i]]\n",
    "    labels[i] = id\n",
    "data = [data[i]/255 for i in range(len(data))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(labels, dtype=np.uint8)\n",
    "data = np.array(data, dtype=np.uint8)\n",
    "print(type(data))\n",
    "print(type(labels))\n",
    "assert data.shape[0] == labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36576\n",
      "36576\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32918\n",
      "3658\n",
      "32918\n",
      "3658\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.1)\n",
    "print(len(data_train))\n",
    "print(len(data_test))\n",
    "print(len(labels_train))\n",
    "print(len(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADcklEQVR4nO3dMXLEIBAAQcvl/38Z546wSuKEpju+QMnUBhzLMcYYX8CrfX/6A4D7CR0ChA4BQocAoUOA0CFA6BAgdAgQOgT8zP7wOI47vwM4aebPrSY6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CJh+wIF1Zhby8wy7PGxiokOA0CFA6BAgdAgQOgQIHQKEDgHO0RdzRs4nmOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4D76Bdbcd98l13iPIeJDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0CLJ54IIsluJqJDgFChwChQ4DQIUDoECB0CBA6BDhH/6cVDzTA1Ux0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BBg8cRiHmfgE0x0CBA6BAgdAoQOAUKHAKFDgNAhwDn6Hx5o4I1MdAgQOgQIHQKEDgFChwChQ4DQIcA5+mLO6a/jbv88Ex0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BKQWT6xY+mAZAk9kokOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAan76Fdw35wdmegQIHQIEDoECB0ChA4BQocAoUPAq87RV+xthx2Z6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAh4FWLJ67ggQbeyESHAKFDgNAhQOgQIHQIEDoECB0CtjpH90ADnGOiQ4DQIUDoECB0CBA6BAgdAoQOAVudo6/grH4N9/7XMtEhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDwFYPOFj6D+eY6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFg+gGHMcad3wHcyESHAKFDgNAhQOgQIHQIEDoECB0ChA4BQoeAXz6WKhFxlKD1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ut.show(data_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 36)                9252      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100836 (393.89 KB)\n",
      "Trainable params: 100836 (393.89 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 18:21:00.791268: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(\n",
    "        input_shape = (28,28,1)\n",
    "    )\n",
    "    ,tf.keras.layers.Dense(\n",
    "        units = 64\n",
    "        ,activation=\"sigmoid\"\n",
    "    )\n",
    "    ,tf.keras.layers.Dense(\n",
    "        units = 128\n",
    "        ,activation = \"sigmoid\"\n",
    "    )\n",
    "    ,tf.keras.layers.Dense(\n",
    "        units = 256\n",
    "        ,activation=\"sigmoid\"\n",
    "    )\n",
    "    ,tf.keras.layers.Dense(\n",
    "        units = 36\n",
    "        ,activation = \"softmax\"\n",
    "    )\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "1029/1029 [==============================] - 4s 3ms/step - loss: 1.9057 - accuracy: 0.5248\n",
      "Epoch 2/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.6680 - accuracy: 0.8404\n",
      "Epoch 3/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.4849 - accuracy: 0.8746\n",
      "Epoch 4/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.3948 - accuracy: 0.8949\n",
      "Epoch 5/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.3324 - accuracy: 0.9078\n",
      "Epoch 6/128\n",
      "1029/1029 [==============================] - 5s 5ms/step - loss: 0.2828 - accuracy: 0.9203\n",
      "Epoch 7/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.2476 - accuracy: 0.9288\n",
      "Epoch 8/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.2154 - accuracy: 0.9366\n",
      "Epoch 9/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.1882 - accuracy: 0.9447\n",
      "Epoch 10/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.1671 - accuracy: 0.9495\n",
      "Epoch 11/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.1458 - accuracy: 0.9550\n",
      "Epoch 12/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.1311 - accuracy: 0.9594\n",
      "Epoch 13/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.1147 - accuracy: 0.9634\n",
      "Epoch 14/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.1016 - accuracy: 0.9688\n",
      "Epoch 15/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0916 - accuracy: 0.9722\n",
      "Epoch 16/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0819 - accuracy: 0.9739\n",
      "Epoch 17/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0730 - accuracy: 0.9770\n",
      "Epoch 18/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0681 - accuracy: 0.9785\n",
      "Epoch 19/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0598 - accuracy: 0.9804\n",
      "Epoch 20/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0561 - accuracy: 0.9814\n",
      "Epoch 21/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0512 - accuracy: 0.9827\n",
      "Epoch 22/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0468 - accuracy: 0.9841\n",
      "Epoch 23/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0450 - accuracy: 0.9854\n",
      "Epoch 24/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0417 - accuracy: 0.9854\n",
      "Epoch 25/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0370 - accuracy: 0.9878\n",
      "Epoch 26/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0399 - accuracy: 0.9865\n",
      "Epoch 27/128\n",
      "1029/1029 [==============================] - 5s 5ms/step - loss: 0.0350 - accuracy: 0.9881\n",
      "Epoch 28/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0357 - accuracy: 0.9883\n",
      "Epoch 29/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0308 - accuracy: 0.9898\n",
      "Epoch 30/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0312 - accuracy: 0.9898\n",
      "Epoch 31/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0307 - accuracy: 0.9891\n",
      "Epoch 32/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0281 - accuracy: 0.9898\n",
      "Epoch 33/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0290 - accuracy: 0.9902\n",
      "Epoch 34/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0229 - accuracy: 0.9922\n",
      "Epoch 35/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0338 - accuracy: 0.9888\n",
      "Epoch 36/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0232 - accuracy: 0.9915\n",
      "Epoch 37/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0201 - accuracy: 0.9929\n",
      "Epoch 38/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0273 - accuracy: 0.9904\n",
      "Epoch 39/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0245 - accuracy: 0.9910\n",
      "Epoch 40/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0211 - accuracy: 0.9926\n",
      "Epoch 41/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0209 - accuracy: 0.9922\n",
      "Epoch 42/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0228 - accuracy: 0.9915\n",
      "Epoch 43/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0169 - accuracy: 0.9938\n",
      "Epoch 44/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0181 - accuracy: 0.9937\n",
      "Epoch 45/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0260 - accuracy: 0.9911\n",
      "Epoch 46/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0156 - accuracy: 0.9943\n",
      "Epoch 47/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0228 - accuracy: 0.9917\n",
      "Epoch 48/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0144 - accuracy: 0.9949\n",
      "Epoch 49/128\n",
      "1029/1029 [==============================] - 3s 2ms/step - loss: 0.0200 - accuracy: 0.9925\n",
      "Epoch 50/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0170 - accuracy: 0.9942\n",
      "Epoch 51/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0183 - accuracy: 0.9932\n",
      "Epoch 52/128\n",
      "1029/1029 [==============================] - 3s 2ms/step - loss: 0.0222 - accuracy: 0.9921\n",
      "Epoch 53/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0126 - accuracy: 0.9955\n",
      "Epoch 54/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0213 - accuracy: 0.9922\n",
      "Epoch 55/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0105 - accuracy: 0.9962\n",
      "Epoch 56/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0205 - accuracy: 0.9929\n",
      "Epoch 57/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0148 - accuracy: 0.9950\n",
      "Epoch 58/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0167 - accuracy: 0.9937\n",
      "Epoch 59/128\n",
      "1029/1029 [==============================] - 5s 5ms/step - loss: 0.0117 - accuracy: 0.9959\n",
      "Epoch 60/128\n",
      "1029/1029 [==============================] - 5s 5ms/step - loss: 0.0190 - accuracy: 0.9934\n",
      "Epoch 61/128\n",
      "1029/1029 [==============================] - 4s 4ms/step - loss: 0.0160 - accuracy: 0.9943\n",
      "Epoch 62/128\n",
      "1029/1029 [==============================] - 5s 4ms/step - loss: 0.0145 - accuracy: 0.9946\n",
      "Epoch 63/128\n",
      "1029/1029 [==============================] - 5s 5ms/step - loss: 0.0135 - accuracy: 0.9954\n",
      "Epoch 64/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0152 - accuracy: 0.9948\n",
      "Epoch 65/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0101 - accuracy: 0.9964\n",
      "Epoch 66/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0143 - accuracy: 0.9946\n",
      "Epoch 67/128\n",
      "1029/1029 [==============================] - 3s 2ms/step - loss: 0.0159 - accuracy: 0.9945\n",
      "Epoch 68/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0138 - accuracy: 0.9947\n",
      "Epoch 69/128\n",
      "1029/1029 [==============================] - 3s 2ms/step - loss: 0.0103 - accuracy: 0.9963\n",
      "Epoch 70/128\n",
      "1029/1029 [==============================] - 3s 2ms/step - loss: 0.0137 - accuracy: 0.9950\n",
      "Epoch 71/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0162 - accuracy: 0.9943\n",
      "Epoch 72/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0085 - accuracy: 0.9971\n",
      "Epoch 73/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0180 - accuracy: 0.9939\n",
      "Epoch 74/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0104 - accuracy: 0.9964\n",
      "Epoch 75/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0105 - accuracy: 0.9964\n",
      "Epoch 76/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0151 - accuracy: 0.9951\n",
      "Epoch 77/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0131 - accuracy: 0.9957\n",
      "Epoch 78/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0095 - accuracy: 0.9966\n",
      "Epoch 79/128\n",
      "1029/1029 [==============================] - 3s 2ms/step - loss: 0.0131 - accuracy: 0.9950\n",
      "Epoch 80/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0090 - accuracy: 0.9966\n",
      "Epoch 81/128\n",
      "1029/1029 [==============================] - 3s 2ms/step - loss: 0.0107 - accuracy: 0.9964\n",
      "Epoch 82/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0116 - accuracy: 0.9957\n",
      "Epoch 83/128\n",
      "1029/1029 [==============================] - 3s 2ms/step - loss: 0.0130 - accuracy: 0.9954\n",
      "Epoch 84/128\n",
      "1029/1029 [==============================] - 3s 2ms/step - loss: 0.0152 - accuracy: 0.9946\n",
      "Epoch 85/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0059 - accuracy: 0.9981\n",
      "Epoch 86/128\n",
      "1029/1029 [==============================] - 3s 2ms/step - loss: 0.0115 - accuracy: 0.9956\n",
      "Epoch 87/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0149 - accuracy: 0.9943\n",
      "Epoch 88/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0098 - accuracy: 0.9964\n",
      "Epoch 89/128\n",
      "1029/1029 [==============================] - 3s 2ms/step - loss: 0.0118 - accuracy: 0.9957\n",
      "Epoch 90/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0082 - accuracy: 0.9970\n",
      "Epoch 91/128\n",
      "1029/1029 [==============================] - 3s 2ms/step - loss: 0.0093 - accuracy: 0.9965\n",
      "Epoch 92/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0108 - accuracy: 0.9962\n",
      "Epoch 93/128\n",
      "1029/1029 [==============================] - 3s 2ms/step - loss: 0.0118 - accuracy: 0.9958\n",
      "Epoch 94/128\n",
      "1029/1029 [==============================] - 3s 2ms/step - loss: 0.0064 - accuracy: 0.9975\n",
      "Epoch 95/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0145 - accuracy: 0.9954\n",
      "Epoch 96/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0087 - accuracy: 0.9969\n",
      "Epoch 97/128\n",
      "1029/1029 [==============================] - 3s 2ms/step - loss: 0.0120 - accuracy: 0.9955\n",
      "Epoch 98/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0102 - accuracy: 0.9961\n",
      "Epoch 99/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0086 - accuracy: 0.9968\n",
      "Epoch 100/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0066 - accuracy: 0.9978\n",
      "Epoch 101/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0108 - accuracy: 0.9963\n",
      "Epoch 102/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0074 - accuracy: 0.9973\n",
      "Epoch 103/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0091 - accuracy: 0.9966\n",
      "Epoch 104/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0095 - accuracy: 0.9965\n",
      "Epoch 105/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0102 - accuracy: 0.9963\n",
      "Epoch 106/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0071 - accuracy: 0.9975\n",
      "Epoch 107/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0071 - accuracy: 0.9975\n",
      "Epoch 108/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0106 - accuracy: 0.9965\n",
      "Epoch 109/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0093 - accuracy: 0.9966\n",
      "Epoch 110/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0125 - accuracy: 0.9958\n",
      "Epoch 111/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0061 - accuracy: 0.9979\n",
      "Epoch 112/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0119 - accuracy: 0.9960\n",
      "Epoch 113/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0058 - accuracy: 0.9978\n",
      "Epoch 114/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0102 - accuracy: 0.9962\n",
      "Epoch 115/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0070 - accuracy: 0.9976\n",
      "Epoch 116/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0071 - accuracy: 0.9978\n",
      "Epoch 117/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0103 - accuracy: 0.9964\n",
      "Epoch 118/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0059 - accuracy: 0.9978\n",
      "Epoch 119/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0105 - accuracy: 0.9964\n",
      "Epoch 120/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0055 - accuracy: 0.9978\n",
      "Epoch 121/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0119 - accuracy: 0.9959\n",
      "Epoch 122/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 123/128\n",
      "1029/1029 [==============================] - 4s 3ms/step - loss: 0.0086 - accuracy: 0.9974\n",
      "Epoch 124/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0107 - accuracy: 0.9961\n",
      "Epoch 125/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0094 - accuracy: 0.9969\n",
      "Epoch 126/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0068 - accuracy: 0.9974\n",
      "Epoch 127/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0049 - accuracy: 0.9981\n",
      "Epoch 128/128\n",
      "1029/1029 [==============================] - 3s 3ms/step - loss: 0.0118 - accuracy: 0.9964\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history =  model.fit(\n",
    "    data_train\n",
    "    ,labels_train\n",
    "    ,epochs = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.9265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6214838624000549, 0.9264625310897827]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ann_6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ann_6/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./models/ann_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(\n",
    "        input_shape = (28,28,1)\n",
    "    )\n",
    "    ,tf.keras.layers.Dense(\n",
    "        units = 64\n",
    "        ,activation=\"relu\"\n",
    "    )\n",
    "    ,tf.keras.layers.Dense(\n",
    "        units = 128\n",
    "        ,activation = \"relu\"\n",
    "    )\n",
    "    ,tf.keras.layers.Dense(\n",
    "        units = 256\n",
    "        ,activation=\"relu\"\n",
    "    )\n",
    "    ,tf.keras.layers.Dense(\n",
    "        units = 36\n",
    "        ,activation = \"softmax\"\n",
    "    )\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import data_preparation as dp\n",
    "import cv2 as cv\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_key(item):\n",
    "    for key, _item in classes.items():\n",
    "        if item == _item:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    ut.show(img[0])\n",
    "    y = loaded_model.predict(img)\n",
    "    y = y.tolist()\n",
    "    y = y[0]\n",
    "    ids = list(range(36))\n",
    "    y = list(zip(y, ids))\n",
    "    y = sorted(y, key = lambda y: y[0])\n",
    "    print(y[-1])\n",
    "    r = find_key(y[-1][1])\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 0, 'H': 1, '0': 2, 'Q': 3, 'V': 4, '9': 5, 'A': 6, 'K': 7, '4': 8, '5': 9, 'E': 10, '2': 11, 'G': 12, '7': 13, 'M': 14, 'U': 15, 'Y': 16, 'I': 17, 'W': 18, 'Z': 19, 'D': 20, 'P': 21, 'N': 22, 'S': 23, 'F': 24, '1': 25, '6': 26, '3': 27, 'L': 28, 'C': 29, 'X': 30, 'R': 31, '8': 32, 'O': 33, 'J': 34, 'T': 35}\n"
     ]
    }
   ],
   "source": [
    "classes = ut.loadData(\"./models/classes\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 36)                9252      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100836 (393.89 KB)\n",
      "Trainable params: 100836 (393.89 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ann 5 works well\n",
    "# ann 6 works well\n",
    "loaded_model = load_model(\"./models/ann_6\")\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADX0lEQVR4nO3cMW7DMBAAwTDQ/7/MtAESQEpgiZJ3pnZxzeKKkznmnPMDeGufqwcAzid0CBA6BAgdAoQOAUKHAKFDgNAhQOgQsB394RjjzDmAfzrycauNDgFChwChQ4DQIUDoECB0CBA6BBy+o/Mad3jQxzcRPTY6BAgdAoQOAUKHAKFDgNAhQOgQ4I7+Yne4k++5Yka3+nux0SFA6BAgdAgQOgQIHQKEDgFChwChQ4APZjjF3kc5Pqi5lo0OAUKHAKFDgNAhQOgQIHQIEDoEuKM/0BU36Cc8oMFxNjoECB0ChA4BQocAoUOA0CFA6BDgjs6v9m717uzPYqNDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUPAtnoA7mnOuXoEXshGhwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0C/B/9gZ7wX/ExxuoR+MZGhwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BHp54II868Fc2OgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BAgdAoQOAUKHAKFDgNAhQOgQIHQIEDoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CBA6BGyrB3g3Y4zVI8APNjoECB0ChA4BQocAoUOA0CFA6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoECB0CDj88MSc88w5gBPZ6BAgdAgQOgQIHQKEDgFChwChQ4DQIUDoEPAF+YEkBXwAstsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "(0.999909520149231, 21)\n",
      "P\n"
     ]
    }
   ],
   "source": [
    "img = cv.imread(\"/home/lenin/Documents/chars/p.png\", cv.IMREAD_GRAYSCALE)\n",
    "img = dp.prepare_img(img)\n",
    "predict(img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
